{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b821e9d7-7b2b-420e-b945-089fc6ee649e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when,  regexp_replace, udf, expr\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"Databricks_Catalog_Read\").getOrCreate()\n",
    "\n",
    "# Define the catalog and schema\n",
    "catalog_name = \"workspace\"\n",
    "schema_name = \"default\"\n",
    "\n",
    "# Read data from Databricks tables and convert them to Pandas DataFrames\n",
    "\n",
    "table_full_path = f\"{catalog_name}.{schema_name}.{'pinterest_data'}\"\n",
    "    \n",
    "# Read the table using Spark\n",
    "df_pin = spark.read.table(table_full_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15263621-092d-46ec-9cba-84bae47ad04e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_pin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc8acf36-7933-430f-9bf6-26970ea211b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define patterns to replace with None\n",
    "replace_patterns = [\n",
    "    (\".*User Info Error.*\", None),\n",
    "    (\".*N,o, ,T,a,g,s, ,A,v,a,i,l,a,b,l,e.*\", None),\n",
    "    (\".*No description available Story format.*\", None),\n",
    "    (\".*No Title Data Available.*\", None),\n",
    "    (\".*Image src error.*\", None),\n",
    "    (\".*No description available.*\",None)\n",
    "]\n",
    "\n",
    "# Iterate over all string columns and apply batch replace\n",
    "for column in df_pin.columns:\n",
    "    # Only process string columns\n",
    "    if dict(df_pin.dtypes)[column] in [\"string\"]:\n",
    "        df_pin = df_pin.withColumn(column, when(col(column) == \"\", None).otherwise(col(column)))  # Replace empty strings with None\n",
    "\n",
    "        for pattern, replacement in replace_patterns:\n",
    "            df_pin = df_pin.withColumn(column, when(col(column).rlike(pattern), None).otherwise(col(column)))\n",
    "\n",
    "\n",
    "#Dropping rows with any null values\n",
    "df_pin = df_pin.dropna(how=\"any\")\n",
    "\n",
    "# Remove \"Local save in \" from the 'save_location' column\n",
    "df_pin = df_pin.withColumn(\"save_location\", regexp_replace(col(\"save_location\"), \"Local save in \", \"\"))\n",
    "\n",
    "#Add \n",
    "df_pin = df_pin.withColumn(\n",
    "    \"follower_count\",\n",
    "    when(col(\"follower_count\").endswith(\"k\"), regexp_replace(col(\"follower_count\"), \"k\", \"000\"))\n",
    "    .when(col(\"follower_count\").endswith(\"M\"), regexp_replace(col(\"follower_count\"), \"M\", \"000000\"))\n",
    "    .otherwise(col(\"follower_count\"))\n",
    ")\n",
    "\n",
    "# Convert the column to integer type\n",
    "df_pin = df_pin.withColumn(\"follower_count\", col(\"follower_count\").cast(\"int\"))\n",
    "\n",
    "# Rename 'index' column to 'ind'\n",
    "df_pin = df_pin.withColumnRenamed(\"index\", \"ind\")\n",
    "\n",
    "# Reorder columns in the specified order\n",
    "df_pin = df_pin.select(\"ind\", \n",
    "                 \"unique_id\", \n",
    "                 \"title\", \n",
    "                 \"description\", \n",
    "                 \"follower_count\", \n",
    "                 \"poster_name\", \n",
    "                 \"tag_list\", \n",
    "                 \"is_image_or_video\", \n",
    "                 \"image_src\", \n",
    "                 \"save_location\", \n",
    "                 \"category\")\n",
    "\n",
    "\n",
    "\n",
    "#Cast df_pin as string\n",
    "df_pin = df_pin.withColumn(\"ind\", col(\"ind\").cast(\"bigint\"))\n",
    "\n",
    "# Show the result\n",
    "display(df_pin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f174c510-5cfe-445c-8ef3-4156f1dbd437",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# Drop the existing table if it exists\n",
    "spark.sql(\"DROP TABLE IF EXISTS workspace.default.df_pin\")\n",
    "\n",
    "# Save Spark DataFrame as managed delta table\n",
    "df_pin.write.mode(\"overwrite\").saveAsTable(\"workspace.default.df_pin\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Load_Transform_Pinterest_Data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
